{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067b30e6-835f-4b74-8ac0-d49c73706730",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %pip install --quiet openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afcc3aa8-f035-4d09-87ef-e4d1248eb95f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, random, re\n",
    "from typing import Optional, Dict\n",
    "from pyspark.sql import Row\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Silence MLflow tracing warnings completely ---\n",
    "import warnings\n",
    "import logging\n",
    "import mlflow\n",
    "\n",
    "# Disable MLflow autologging and tracing\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# Turn off loggers for MLflow and tracing\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"mlflow.tracing\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"mlflow.tracing.export.mlflow_v3\").setLevel(logging.CRITICAL)\n",
    "\n",
    "# Suppress all warnings containing 'mlflow.tracing'\n",
    "warnings.filterwarnings(\"ignore\", message=\".*mlflow.tracing.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*trace to MLflow backend.*\", category=UserWarning)\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7141ea24-f148-412b-91eb-ce26369d132e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1) Auth —— put your key in env or use Databricks Secrets\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"   \n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a217224c-ccd1-4188-a56c-a5c09e9c9f0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 2) Fetch context for a single user (adjust fields if you add more)\n",
    "def fetch_prompt_context(user_id: int) -> Optional[Dict]:\n",
    "    row: Optional[Row] = (spark.table(\"instacart.gold.customer_segments\")\n",
    "                          .where(f\"user_id = {int(user_id)}\")\n",
    "                          .select(\n",
    "                              \"user_id\",\"temporal_group\",\"engagement_group\",\n",
    "                              \"preferred_window\",\"dominant_dow\",\"dominant_hour\",\n",
    "                              \"mean_days_between_orders\",\"last_gap_days\",\n",
    "                              \"top_product_1\",\"top_product_2\",\"top_product_3\"\n",
    "                          )\n",
    "                          .limit(1)\n",
    "                          .collect()[0] if spark.table(\"instacart.gold.customer_segments\").where(f\"user_id = {int(user_id)}\").count() > 0 else None)\n",
    "    if not row:\n",
    "        return None\n",
    "    d = row.asDict()\n",
    "    # small helpers\n",
    "    dow_map = [\"Sun\",\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\"]\n",
    "    d[\"dominant_dow_label\"] = dow_map[int(d[\"dominant_dow\"])]\n",
    "    d[\"top_products\"] = [p for p in [d[\"top_product_1\"], d[\"top_product_2\"], d[\"top_product_3\"]] if p]\n",
    "    return d\n",
    "\n",
    "# 3) Build prompt (EDIT THESE SECTIONS freely)\n",
    "def build_prompt(ctx: Dict, style: str = \"friendly\") -> str:\n",
    "    return f\"\"\"\n",
    "[ROLE]\n",
    "You are a retention copywriter. Write a concise, on-brand push notification.\n",
    "\n",
    "[GOAL]\n",
    "Nudge the user to reorder around their usual time window with 1–2 favorite items.\n",
    "\n",
    "[CONSTRAINTS]\n",
    "- 18–28 words, plain language, no emojis.\n",
    "- Include exactly one product if available.\n",
    "- Match tone to engagement group. Be respectful if at-risk.\n",
    "- Do NOT fabricate data.\n",
    "\n",
    "[USER CONTEXT]\n",
    "user_id: {ctx['user_id']}\n",
    "temporal_group: {ctx['temporal_group']}\n",
    "engagement_group: {ctx['engagement_group']}\n",
    "preferred_window: {ctx['preferred_window']}\n",
    "dominant_dow: {ctx['dominant_dow_label']}\n",
    "dominant_hour: {int(ctx['dominant_hour'])}:00\n",
    "mean_gap_days: {round(float(ctx['mean_days_between_orders']),1)}\n",
    "last_gap_days: {round(float(ctx['last_gap_days']),1)}\n",
    "fav_products: {\", \".join(ctx[\"top_products\"]) if ctx[\"top_products\"] else \"N/A\"}\n",
    "\n",
    "[STYLE]\n",
    "tone: {style}\n",
    "brand: practical, helpful, time-aware\n",
    "\n",
    "[OUTPUT]\n",
    "One push notification line. No preamble, no quotes.\n",
    "\"\"\".strip()\n",
    "\n",
    "# 4) Generate with OpenAI (Responses API). Swap model/params as you like.\n",
    "def generate_notification(user_id: int,\n",
    "                          model: str = \"gpt-4o-mini\",\n",
    "                          temperature: float = 0.7,\n",
    "                          style: str = \"friendly\") -> str:\n",
    "    ctx = fetch_prompt_context(user_id)\n",
    "    if not ctx:\n",
    "        return f\"[no-context] user_id {user_id} not found in customer_segments.\"\n",
    "    prompt = build_prompt(ctx, style=style)\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=model,\n",
    "        input=prompt,\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=60\n",
    "    )\n",
    "    return resp.output_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69287077-0ddf-44e3-b225-b791b3694244",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Reassuring tone, soft CTA, no incentive (at-risk friendly)\n",
    "print(generate_notification(\n",
    "    user_id=47,                 # Late-Night • At-Risk Regular (from your sample)\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.6,\n",
    "    style=\"reassuring\",\n",
    "    cta_mode=\"soft\",\n",
    "    include_incentive=False,\n",
    "    min_words=16, max_words=26, n_variants=6\n",
    "))\n",
    "print()\n",
    "\n",
    "# 2) Energetic tone, standard CTA, include incentive\n",
    "print(generate_notification(\n",
    "    user_id=27,                 # Weekly Shoppers (active)\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.8,\n",
    "    style=\"energetic\",\n",
    "    cta_mode=\"standard\",\n",
    "    include_incentive=True,\n",
    "    min_words=18, max_words=24, n_variants=7\n",
    "))\n",
    "print()\n",
    "\n",
    "# 3) Exclusive tone, urgent CTA (time-sensitive push)\n",
    "print(generate_notification(\n",
    "    user_id=22,                 # Evening Weekend\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7,\n",
    "    style=\"exclusive\",\n",
    "    cta_mode=\"urgent\",\n",
    "    include_incentive=False,\n",
    "    min_words=14, max_words=22, n_variants=6\n",
    "))\n",
    "print()\n",
    "\n",
    "# 4) Minimal tone, standard CTA (short + direct)\n",
    "print(generate_notification(\n",
    "    user_id=53,                 # Morning Weekday\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.5,\n",
    "    style=\"minimal\",\n",
    "    cta_mode=\"standard\",\n",
    "    include_incentive=False,\n",
    "    min_words=12, max_words=18, n_variants=8\n",
    "))\n",
    "print()\n",
    "\n",
    "# 5) Seasonal tone, urgent CTA, include incentive (campaign-style)\n",
    "print(generate_notification(\n",
    "    user_id=76,                 # Morning Weekday\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.9,\n",
    "    style=\"seasonal\",\n",
    "    cta_mode=\"urgent\",\n",
    "    include_incentive=True,\n",
    "    min_words=18, max_words=28, n_variants=6\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "deb1135b-d166-4f74-b991-417a553af625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3-AI-Notification",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
